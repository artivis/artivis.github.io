[{"authors":["admin"],"categories":null,"content":"JÃ©rÃ©mie Deray is a software engineer at Canonical, the company publishing UbuntuÂ . As part of the robotics team he is working on both ROS and ROS 2 - development, maintenance, dev tools, security, snaps\u0026hellip; Before that he worked five years at PAL Robotics on navigation, perception and a little bit of control, this for various robots - mobile-base, mobile-manipulator, semi-humanoid.\nIn parallel, JÃ©rÃ©mie has been pursuing a PhD on the theme of Simultaneous Localization and Mapping (SLAM) applied to industrial mobile-bases. The research is taking place in a collaborative framework between the company PAL Robotics and the Universitat PolitÃ¨cnica De Catalunya (IRI-UPC), both in the lovely city of Barcelona, Spain. The research work is supervised by Joan SolÃ  and Juan Andrade Cetto.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1589831268,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://artivis.github.io/author/jeremie-deray/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jeremie-deray/","section":"authors","summary":"JÃ©rÃ©mie Deray is a software engineer at Canonical, the company publishing UbuntuÂ . As part of the robotics team he is working on both ROS and ROS 2 - development, maintenance, dev tools, security, snaps\u0026hellip; Before that he worked five years at PAL Robotics on navigation, perception and a little bit of control, this for various robots - mobile-base, mobile-manipulator, semi-humanoid.","tags":null,"title":"JÃ©rÃ©mie Deray","type":"authors"},{"authors":null,"categories":null,"content":"Here we are, looking for online visibility. How does one set that up quickly when starting from scratch? Do you Remember those HTML courses?\nYeah me neither.\nBut fortunately for us it is now easier than ever!\nWe will discuss in this post how to create our own website with the Hugo framework from a template and how to deploy it to GitHub. The prerequisites are,\n GitHub markdown  LXD (optional)  You may find GitHub tutorials here and there. Pages of our website will be written in markdown. You can learn more about markdown from those tutorials, in English and in French. And if you only need a brief refresh, here is the syntax supported by our website. Finally, you can find a LXD tutorial here.\nNow, let us set up the necessary stuff to get started, shall we?\nPicking a website template To build our website, we will use the framework Hugo. It is very convenient for our use case because it comes with a ton of predefined website themes and it is very simple to use.\nFor the purpose of this tutorial we will use the very theme of this website, namely, Academic. This theme is rather clean, well organized, fairly simple to use and most importantly it is well documented! Furthermore, it can be found pre-bundled in a Hugo project so that it is pretty much clone and play. However, at the time of writing, this theme requires Hugo *Extended* version 0.67+. This distinction is important because, while it is conveniently packaged as a snap, the snap only offers the classic version, not the Extended. Therefore we have to fetch its debian package and install it manually.\nFirst, let us clone the ready-to-go Academic bundle on our machine:\ncd ~/ git clone https://github.com/sourcethemes/academic-kickstart.git my_website cd my_website git submodule update --init --recursive  Prepping the tools To avoid polluting our system, we will set up a Linux container in which we will install Hugo Extended. The container is totally optional and you can do the installation directly on your machine. If you do not wish to use a container, skip directly to Hugo installation\nSetting up the LXC Let us start a fresh and pull a new Ubuntu 18.04 instance,\nlxc launch ubuntu:18.04 hugo  We will now mount a disk device to share the website source code between our machine and the container:\nlxc config device add hugo workspace disk source=~/my_website path=/home/ubuntu/my_website lxc config set hugo raw.idmap \u0026quot;both $(id -u) $(id -g)\u0026quot; lxc restart hugo  The default installation of LXD set up a bridged network so that containers live behind a NAT on the host. Therefore, we have to forward the port on which our website is served by the Hugo framework. To do so, issue the following command:\nlxc config device add hugo proxy1313 proxy connect=tcp:127.0.0.1:1313 listen=tcp:0.0.0.0:1313  The container is all set up. We can log to it with:\nlxc exec hugo -- su --login ubuntu  Installing Hugo We will download the Hugo extended debian directly from it GitHub repository. To do so, enter in the terminal:\nwget https://github.com/gohugoio/hugo/releases/download/v0.70.0/hugo_extended_0.70.0_Linux-64bit.deb  At the time of writing, the latest Hugo Extended release is version 0.70.0.\nWe can now install it with:\nsudo dpkg -i hugo_extended_*.deb  First view of our website Let the show begin. We are now ready to spawn our website and browse it. In a terminal, enter:\ncd ~/my_website hugo server  Voila!\nThe website it up and running! To visualize it, open your web browser at the address http://localhost:1313. That was easy right?\nMaking the website your own We have a great template up and running, it is now time to make it our own. The Academic theme comes with a ton of options and configurations allowing us to truly personalize it to our liking and use case. And since its online documentation is so great, I will let you discovers by yourself all the possibilities the theme offers. Head down to the Academic get started documentation and have fun!\nJust a quick advice, as you edit your website, let Hugo run. It is able to update the website live so that you see your changes take effect immediately in your web browser!\nDeploying the website to GitHub Once our website is ready to be made public, all there is to do is to push it to GitHub. Well, almost.\nIn your GitHub account, we will create a repository to host your website. To do so hit the tiny cross (+) in the top-right of GitHub and select new repository. For GitHub to be able to figure out that this particular repository is your personal website we need to give it a specific name in the form : \u0026lt;your-github-user-name\u0026gt;.github.io.\nWe will now prepare to push the website to this repository.\nFirst we will add the GitHub repository we just created as our remote,\ngit add remote origin https://github.com/\u0026lt;your-github-user-name\u0026gt;/\u0026lt;your-github-user-name\u0026gt;.github.io.git  and change our branch name to avoid later mess,\ngit branch -m master builder  Here comes the final step before pushing to GitHub. We must build our website, or rather let Hugo do it for us. Indeed so far we have edited the template that Hugo uses to build the website. We have visualized it in our browser but the template cannot be deployed directly to GitHub, it must be built. To build it locally, nothing easier, simply run:\nhugo  You will notice a new folder named public in our project. It contains the generated website. It is this content that we must push to our repository. Furthermore, it must be pushed specifically to the master branch. That\u0026rsquo;s a limitation of personal website on GitHub.\nAutomatic deployment So how could we automatize this build and deploy process?\nWe will add a small script so that every times we push some new content on the builder branch, GitHub will take care of calling Hugo (building) and moving the public folder directly on the master branch (deploying).\nFor that, we will use GitHub actions and more specifically the actions-hugo. Sorry buddy but I\u0026rsquo;ll skip the details about actons here as it is all new to me as well. That could be the topic for a later post tho.\nWe will simply create a new file in our project to configure the action:\ncd ~/my_website touch .github/workflows/deploy-website.yml  which we will edit as follows:\nname: deploy website # We will run the actions whenever something # is pushed to the branch 'builder' on: push: branches: - builder jobs: # Our action is called 'deploy' and runs on Ubuntu 18.04 deploy: runs-on: ubuntu-18.04 # The action executes the following steps steps: # It fetch our repository and its submodules - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod # It then set up Hugo Extended - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: '0.68.3' extended: true # It runs Hugo to generate the website - name: Build run: hugo --minify # It copies the content of the 'public' folder to the branch 'master' - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public publish_branch: master  With our automatic deployment configured, all there remains to do is to push to GitHub!\nLet us remove the \u0026lsquo;public\u0026rsquo; folder is it exists,\ncd ~/my_website rm -r public  and commit all of our changes,\ngit add . git commit 'made the website my own'  Finally, we push the changes upstream,\ngit push origin builder  Voila!\nAfter a couple minutes your website is now available at the address:\nhttps://\u0026lt;your-github-user-name\u0026gt;.github.io/\nCongrats on your new online visibility, our job here is done.\nBonus: Academic publications If you happen to have some academic publications that you would like to showcase on your website, we will install a Python tool called academic that will help us to automatically generate pages from Bibtex.\nFirst we will install pip3:\napt install python3-pip  to then install academic:\npip3 install -U academic  Given that we have a .bib file that contains all of our publications, we can generate the pages as follows:\ncd ~/my_website academic import --bibtex \u0026lt;path_to_your/publications.bib\u0026gt;  You can find more information in the Academic theme documentation.\n","date":1588982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590795601,"objectID":"1935ac9469e8a1f3c15b0c1795f0e181","permalink":"https://artivis.github.io/post/2020/my-website/","publishdate":"2020-05-09T00:00:00Z","relpermalink":"/post/2020/my-website/","section":"post","summary":"Here we are, looking for online visibility. How does one set that up quickly when starting from scratch? Do you Remember those HTML courses?\nYeah me neither.\nBut fortunately for us it is now easier than ever!","tags":["tutorial","website","github","hugo","academic"],"title":"My website","type":"post"},{"authors":null,"categories":null,"content":"In this post, we will discuss how to setup a Linux container - a.k.a LXC - for our ROS Noetic development. Developing in containers has several advantages such as:\n allowing us to use a different Linux distribution than the one we\u0026rsquo;ve installed on our host machine providing a repeatable course of actions messing around, installing a tons of dependencies without polluting our computer burning the container to the ground and starting fresh again easily  There are of course many other upsides but those are the one we are really interested in for now. We will see first how to get started with LXC and install the latest ROS release Noetic. We will then configure our container so that it is able to share a workspace with our host machine. We will also enable the use of graphical applications from the container (e.g. Rviz, Gazebo). We will further personalize our containerized workflow, setting up all of our application configuration files - a.k.a dotfiles.\nThe main prerequisites for this post are to be familiar with:\n the command terminal in Linux ROS development LXC  Note that I will be linking resources throughout the text, make sure to check them whenever you need further information.\nFinally, while we will be focusing on the latest ROS Noetic release, the setup presented here applies not only to other ROS distributions but likely to most projects, be them ROS-based or not.\n Content   Setting up the LXC   LXC aliases to the rescue    Install ROS Noetic  Mounting a local workspace  Using graphical applications   Creating a LXD profile  Dedicated graphic card    Profile all the things!  Setting up dotfiles  Speed up new LXC set up  Wrapping up   Setting up the LXC We will start by installing LXD, a lightweight container hypervisor which extends LXC functionality over the network. LXD uses LXC under the covers for some container management tasks and provides the \u0026lsquo;lxc\u0026rsquo; command line interface tool we will use throughout this post. For more information, you can refer to the LXC and LXD documentation on the Ubuntu website.\nAlright, let us install LXD as a snap to make sure we always run the most up to date stable version:\n$ sudo snap install lxd  Before we can create our first container, we must initialize LXD,\n$ sudo lxd init  This command will prompt you with a bunch of questions to fine tune LXD use. Unless you know what you are doing, you can safely hit the default answers.\nFinally, we will add our user to the \u0026lsquo;lxd\u0026rsquo; group so that we can run lxd commands without sudo,\n$ sudo gpasswd -a \u0026quot;${USER}\u0026quot; lxd  You should log out and log in again for this to take effect.\nCreating the container To create a new container, we will use the following command,\n$ lxc launch {remote}:{image} {container-name}  Since Noetic runs on Ubuntu 20.04, we will fetch a Ubuntu 20.04 image from the official Ubuntu remote,\n$ lxc launch ubuntu:20.04 ros-noetic  We can check that the container was properly created and launched,\n$ lxc list +---------------+---------+-----------------------+-----------------------------------------------+-----------+-----------+ | NAME | STATE | IPV4 | IPV6 | TYPE | SNAPSHOTS | +---------------+---------+-----------------------+-----------------------------------------------+-----------+-----------+ | ros-noetic | RUNNING | 10.160.218.172 (eth0) | dd42:5ke1:fr68:2ca4:236:eff3:fe3r:7c21 (eth0) | CONTAINER | 0 | +---------------+---------+-----------------------+-----------------------------------------------+-----------+-----------+  With our container up and running, we can open a shell in it with a non-root user with the following command,\n$ lxc exec ros-noetic -- sudo --login --user ubuntu  I know, this command is not very pretty nor easy to remember. But worry not, we will create an alias to ease future use.\nLXC aliases to the rescue LXC aliases, just like bash aliases, allow use to create a new CLI keywords to which we can associate an action. The command to create a new alias is,\n$ lxc alias add {alias} '{command}'  As an example, let us create a shorter version of the lxc list command that also prints a more compact result:\n$ lxc alias add ls 'list --format csv -c n'  We can check that the alias is correctly created,\n$ lxc alias list +--------+----------------------------------------------------------------------------------+ | ALIAS | TARGET | +--------+----------------------------------------------------------------------------------+ | ls | list --format csv -c n | +--------+----------------------------------------------------------------------------------+  And we can now simply use it,\n$ lxc ls ros-noetic  That\u0026rsquo;s pretty neat.\nBut our main goal with aliases was to simplify our shell login to the container, so let\u0026rsquo;s just do that. Borrowing from the excellent blog post by Simos Xenitellis about LXC aliases, we will create a new alias \u0026lsquo;ubuntu\u0026rsquo; such as,\n$ lxc alias add ubuntu 'exec @ARGS@ --mode interactive -- /bin/sh -xac $@ubuntu - exec /bin/login -p -f '  This alias allows us now to simply connect to our container with,\n$ lxc ubuntu ros-noetic  That\u0026rsquo;s much better isn\u0026rsquo;t it?\nInstall ROS Noetic  ROS Noetic is the latest and final ROS 1 release. The ROS project hasn\u0026rsquo;t come to an end, on the contrary, it rather look forward and focus its efforts toward the second version, namely ROS 2. Nevertheless, ROS Noetic is an important release because it targets Ubuntu 20.04, has official Python 3 support and will be supported until May 2025 (more information on Noetic wiki page). That leaves us plenty of time to learn and move to ROS 2.\nTo install it, let\u0026rsquo;s first connect to our container using our new LXC alias,\n$ lxc ubuntu ros-noetic  First, we will add the ROS packages repository to our sources. Starting with the key,\n$ apt-key adv --fetch-keys https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc  then the repository,\n$ apt-add-repository http://packages.ros.org/ros/ubuntu  In case of trouble, you can also refer to the official documentation.\nWe are all set to install ROS Noetic!\nHere we can choose either of three installations; we can install only the core components,\n$ sudo apt install ros-noetic-ros-base  or core + the visualization stack (e.g. Rviz),\n$ sudo apt install ros-noetic-desktop  or core + the visualization + simulation stacks (e.g. Gazebo),\n$ sudo apt install ros-noetic-desktop-full  You can pick any depending on your needs. If you are not sure, I would recommend you install only the core components and later install other packages on a per-need basis:\n$ sudo apt install ros-noetic-ros-base ... $ sudo apt install ros-noetic-\u0026lt;package-I-need\u0026gt;  Simply to keep the size of the container as small as possible.\nFinally, we will automatically source Noetic since this container is dedicated to it,\n$ echo \u0026quot;source /opt/ros/noetic/setup.bash\u0026quot; \u0026gt;\u0026gt; ~/.bashrc  Every times we will log into our container, ROS Noetic will be sourced and we will be ready to develop!\nMounting a local workspace What would our development workflow look like without some actual source code to work on? Well, let us set up our ROS workspace.\nRather than copying/creating our workspace in the container, we will keep it on the host machine. By doing so, not only the workspace will survive deleting the LXC (persistence) but we will also be able to share it across several LXC thus across several ROS distros.\nHereafter, we will assume our workspace to be simply ~/workspace on the host with the classic tree,\n$ tree ~/workspace /home/user/workspace/ â””â”€â”€ src â””â”€â”€ my_ros_package â””...  To share a folder with the container, we have to add a \u0026lsquo;device disk\u0026rsquo; to it. The general command to do so is of the form,\n$ lxc config device add {container} {device-name} disk source={full-path-to-folder} path={full-path-inside-container}  filling up the placeholders for our use case, it reads,\n$ lxc config device add ros-noetic workspace disk source=~/workspace path=/home/ubuntu/workspace  Once the device added, we have to configure the access rights so that we can read and write the folder and its content in the container,\n$ lxc config set ros-noetic raw.idmap \u0026quot;both $(id -u) $(id -g)\u0026quot;  We now have to restart the container for the changes to take effects,\n$ lxc restart ros-noetic  Let us log back into our container,\n$ lxc ubuntu ros-noetic  and verify that the folder is properly mounted,\n$ ls -l drwxr-xr-x 22 ubuntu ubuntu 4096 May 22 21:21 workspace  Looks like we are good!\nIn this section we have configured our container through the lxc config cli tool. Note that container configuration is saved in a yaml file, which you can review with,\n$ lxc config show {container}  and directly edit with,\n$ lxc config edit {container}  More on that later.\nUsing graphical applications This part is totally optional and depends on whether you are planning to run some graphical applications (e.g. Rviz, Gazebo) in your container or not. If you are not interested in running any gui in your container, you may still want to have a quick look before jumping at the \u0026lsquo; Profile all the things!\u0026rsquo; section. If you do want to run graphical applications, then we have to configure the container to support that.\nUnlike in the previous section, we are not going to use the lxc config tool to configure our container. Instead, we will introduce lxc profile as a way to create easily reusable configurations.A profile is a set of parameters that can be applied to a container in one go. It can describe a full fledged setup or a particular feature as in our case below. Furthermore a profile can be use by a single container or many. Reusability!\nCreating a LXD profile Let us first create a profile named gui,\n$ lxc profile create gui  we can now edit the profile,\n$ lxc profile edit gui  and paste the following,\nconfig: environment.DISPLAY: :0 raw.idmap: both 1000 1000 description: Enables graphical apps use. devices: X0: path: /tmp/.X11-unix/X0 source: /tmp/.X11-unix/X0 type: disk mygpu: type: gpu name: gui used_by: []  Alternatively, you can use the following one liner,\ncurl https://gist.githubusercontent.com/artivis/37c961e157e99f6fcaff0204a0f59731/raw/ca4abd1a3c6b1d8a74910207903ac7723685dce1/gui.yaml | lxc profile edit gui  In this profile, there might be a couple things for you to tweak depending on your machine. For instance your user id and guid,\nraw.idmap: both 1000 1000  which you can retrieve respectively with:\n$ id -u 1000 $ id -g 1000  You may also have to check your graphic card in use looking at the directory /tmp/.X11-unix/.\nNow that our profile is set up, we have to add it to our container,\nlxc profile add ros-noetic gui  As previously, we have to restart the container for those change to take effect,\nlxc restart ros-noetic  Alright, let us try to open Rviz to make sure everything went fine. Open two shells to the container, one running the roscore and the second running Rviz:\nShell 1\n$ roscore  Shell 2\n$ rosrun rviz rviz  We are getting really close to our regular development experience aren\u0026rsquo;t we?\nDedicated graphic card If you have a dedicated graphic card on your host machine, you will also have to install the very same driver in the container in order to use graphical applications. If you have an Nvidia card, the following should help you. To figure out the driver version on the host we\u0026rsquo;ll type,\n$ nvidia-smi Mon May 12 11:59:59 2020 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 440.82 Driver Version: 440.82 CUDA Version: 10.2 | +-------------------------------+----------------------+----------------------+  All we have to do now is to install the same driver in the container,\n$ sudo apt install nvidia-440  Setting up dotfiles âš  ðŸš§ [Under construction ðŸ‘·] ðŸš§ âš \n Because there is no place like $HOME.\n $ git clone git://github.com/andsens/homeshick.git $HOME/.homesick/repos/homeshick $ source \u0026quot;$HOME/.homesick/repos/homeshick/homeshick.sh\u0026quot; $ homeshick --batch clone git@github.com:username/dotfiles $ homeshick link $ echo \u0026quot;source ~/dotfiles/.bash_mysources\u0026quot; \u0026gt;\u0026gt; ~/.bashrc $ source ~/.bashrc  Profile all the things We have seen in section \u0026lsquo;Creating a LXD profile\u0026rsquo; how to create a LXC profile to easily support running graphical apps in our container(s). As we mentioned before, a profile really only is a set of configurations for our container. So one may ask\n can\u0026rsquo;t we create some other profiles to further group all the configs we\u0026rsquo;ve seen?\n Well, yes we can! And guess what? Containers can have several profiles! So we could totally create another profile to automatically add the ROS apt repository, both for ROS 1 and ROS 2 respectively:\n$ lxc profile create ros-apt $ lxc profile edit ros-apt  and add,\nconfig: user.user-data: | #cloud-config runcmd: - \u0026quot;apt-key adv --fetch-keys https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc\u0026quot; - \u0026quot;apt-add-repository http://packages.ros.org/ros/ubuntu\u0026quot; - \u0026quot;apt-add-repository http://packages.ros.org/ros2/ubuntu\u0026quot; description: \u0026quot;Add ROS apt repository\u0026quot; devices: {} name: ros used_by: {}  Similarly we could create another profile to easily share our ROS workspace as well,\n$ lxc profile create ros-ws $ lxc profile edit ros-ws  and add,\nconfig: raw.idmap: both 1000 1000 description: \u0026quot;Share the ROS workspace\u0026quot; devices: workspaces: path: /home/ubuntu/workspace source: /home/user/workspace type: disk name: ros-ws used_by: {}  And remember to tweak both profiles (user id/guid etc.).\nBoth profiles will greatly help when creating a new container. However, before we get all excited, let me tell you that we have to be cautious when using them. The reason is that both should be added a rather specific times of the container creation. Let us see when that is.\nFirst, the \u0026lsquo;ros-apt\u0026rsquo; profile makes use of cloud-init to preconfigure the container meaning that our apt-key/apt-add-repository command will be run only once when the container is first created (see this other blog post by Simos Xenitellis for more info about cloud-init in LXD). To create a container with given profile(s), the lxc launch commands changes to,\n$ lxc launch --profile {profile-a} --profile {profile-b} {remote}:{image} {container-name}  which in our case looks like,\n$ lxc launch --profile default --profile ros-apt ubuntu:20.04 ros-noetic2  Let me insist again. If you try to add the \u0026lsquo;ros-apt\u0026rsquo; profile after the container was created, nothing will happen: lxd profile add ros-noetic ros-apt!\nConcerning our \u0026lsquo;ros-ws\u0026rsquo; profile, it is a bit of the opposite situation. Indeed, when creating the container, a whole bunch of things are ran before the \u0026lsquo;ubuntu\u0026rsquo; user is set up. Since we are linking our workspace to /home/ubuntu/ we may arrive to early so to speak and it results in messing up the proper set up of the user. For this profile, we therefore have to add it after the container creation (lxc launch --profile ros-ws {remote}:{image} {container-name}).\nWe can add our ros-ws profile to a container with,\n$ lxc profile add ros-noetic ros-ws  This whole tempo story sounds annoying. Alright let\u0026rsquo;s call it a day and summarize how to set up a new container.\nWrapping up Well, that was quite a journey in LXD realm. But our efforts were not vain for we have learned a lot about LXD and set up some great tools.\nSoon, the ROS 2 Foxy distro will be released (5th of June). How will we then create a Foxy container? Well, that\u0026rsquo;s quite simple now:\n$ lxc launch --profile default --profile ros-apt --profile gui ubuntu:20.04 ros-foxy $ lxc profile add ros-foxy ros-ws $ lxc ubuntu ros-foxy ... $ sudo apt install ros-foxy-desktop  Off we go!\n","date":1588982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590796297,"objectID":"6e9ac8c4106f150dee9ba7aed739cb49","permalink":"https://artivis.github.io/post/2020/lxc/","publishdate":"2020-05-09T00:00:00Z","relpermalink":"/post/2020/lxc/","section":"post","summary":"In this post, we will discuss how to setup a Linux container - a.k.a LXC - for our ROS Noetic development. Developing in containers has several advantages such as:\n allowing us to use a different Linux distribution than the one we\u0026rsquo;ve installed on our host machine providing a repeatable course of actions messing around, installing a tons of dependencies without polluting our computer burning the container to the ground and starting fresh again easily  There are of course many other upsides but those are the one we are really interested in for now.","tags":["tutorial","LXC","LXD","ROS","Ubuntu","dotfiles"],"title":"ROS Noetic development workflow in LXC","type":"post"},{"authors":["J. Deray","J. SolÃ "],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589060872,"objectID":"7fa3cd8f940f34b8f7a680163f4018be","permalink":"https://artivis.github.io/publication/deray-joss-20/","publishdate":"2020-05-09T22:12:35.024894Z","relpermalink":"/publication/deray-joss-20/","section":"publication","summary":"","tags":null,"title":"Manif: A micro Lie theory library for state estimation in robotics applications","type":"publication"},{"authors":["J. Deray","B. Magyar","J. SolÃ ","J. Andrade-Cetto"],"categories":null,"content":"","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589060872,"objectID":"c85af36e1eed8e87dcbf3bc0775a3489","permalink":"https://artivis.github.io/publication/deray-iros-19/","publishdate":"2020-05-09T22:12:35.024619Z","relpermalink":"/publication/deray-iros-19/","section":"publication","summary":"This paper proposes the use of piecewise C^n smooth curve for mobile-base motion planning and control, coined Timed-Elastic Smooth Curve (TESC) planner. Based on a Timed-Elastic Band, the problem is defined so that the trajectory lies on a spline in SE(2) with non-vanishing n-th derivatives at every point. Formulated as a multi-objective nonlinear optimization problem, it allows imposing soft constraints such as collision-avoidance, velocity, acceleration and jerk limits, and more. The planning process is realtime-capable allowing the robot to navigate in dynamic complex scenarios. The proposed method is compared against the state-of-the-art in various scenarios. Results show that trajectories generated by the TESC planner have smaller average acceleration and are more efficient in terms of total curvature and pseudo-kinetic energy while being produced with more consistency than state-of-the-art planners do.","tags":null,"title":"Timed-elastic smooth curve optimization for mobile-base motion planning","type":"publication"},{"authors":["B. Magyar","N. Tsiogkas","J. Deray","S. Pfeiffer","D. Lane"],"categories":null,"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589060872,"objectID":"fb969b8e309ab70a3bcc5186994d3c71","permalink":"https://artivis.github.io/publication/magyar-ral-19/","publishdate":"2020-05-09T22:12:35.024339Z","relpermalink":"/publication/magyar-ral-19/","section":"publication","summary":"Motion planning is one of the main problems studied in the field of robotics. However, it is still challenging for the state-of-the-art methods to handle multiple conditions that allow better paths to be found. For example, considering joint limits, path smoothness and a mixture of Cartesian and joint-space constraints at the same time pose a significant challenge for many of them. This letter proposes to use timed-elastic bands for representing the manipulation motion planning problem, allowing to apply continuously optimized constraints to the problem during the search for a solution. Due to the nature of our method, it is highly extensible with new constraints or optimization objectives. The proposed approach is compared against state-of-the-art methods in various manipulation scenarios. The results show that it is more consistent and less variant, while performing in a comparable manner to that of the state of the art. This behavior allows the proposed method to set a lower-bound performance guarantee for other methods to build upon.","tags":null,"title":"Timed-Elastic Bands for Manipulation Motion Planning","type":"publication"},{"authors":["J. Deray","J. SolÃ ","J. Andrade-Cetto"],"categories":null,"content":"","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589060872,"objectID":"d45f264f27e2c46ce1db468c8ab920ef","permalink":"https://artivis.github.io/publication/deray-ecmr-19/","publishdate":"2020-05-09T22:12:35.024059Z","relpermalink":"/publication/deray-ecmr-19/","section":"publication","summary":"This paper describes a self-calibration procedure that jointly estimates the extrinsic parameters of an exteroceptive sensor able to observe ego-motion, and the intrinsic parameters of an odometry motion model, consisting of wheel radii and wheel separation. We use iterative nonlinear on-manifold optimization with a graphical representation of the state, and resort to an adaptation of the pre-integration theory, initially developed for the IMU motion sensor, to be applied to the differential drive motion model. For this, we describe the construction of a pre-integrated factor for the differential drive motion model, which includes the motion increment, its covariance, and a first-order approximation of its dependence with the calibration parameters. As the calibration parameters change at each solver iteration, this allows a posteriori factor correction without the need of re-integrating the motion data. We validate our proposal in simulations and on a real robot and show the convergence of the calibration towards the true values of the parameters. It is then tested online in simulation and is shown to accommodate to variations in the calibration parameters when the vehicle is subject to physical changes such as loading and unloading a freight.","tags":["Calibration;Robot sensing systems;Wheels;Kinematics;Jacobian matrices;Mobile robots"],"title":"Joint on-manifold self-calibration of odometry model and sensor extrinsics using pre-integration","type":"publication"},{"authors":null,"categories":null,"content":"We will find in a near future more and more robots in our environment, including public places (e.g. malls, museums, hospitals). This requires a strong robustness in any task to ensure the safety of both people and robots. If nowadays we can find pretty accurate sensors (e.g. laser range finder), they however are of little help in crowded places. Especially since humanoid robots are still a curiosity for the public and as such are often completely surrounded. This is why it is important to investigate sensors which provide as much information as possible for the lowest cost possible. Omnidirectional cameras are well suited for this task. Indeed as shown in this thesis, two fisheye cameras are enough to get a full 360Â° view of the robot environment. This permits in a first place the robot to localize itself and in a second place, any usual use of camera can be adapted such as navigation, face detection etc.\nYoutube video     Few Images ","date":1530144000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589060872,"objectID":"824d9f18212c0aa7d4461c87a1cf1ac6","permalink":"https://artivis.github.io/project/mscv_thesis/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/project/mscv_thesis/","section":"project","summary":"We will find in a near future more and more robots in our environment, including public places (e.g. malls, museums, hospitals). This requires a strong robustness in any task to ensure the safety of both people and robots.","tags":null,"title":"MSc Thesis","type":"project"},{"authors":["Joan SolÃ ","Jeremie Deray","Dinesh Atchuthan"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589060872,"objectID":"000f76c98004a939852ee292393c6e91","permalink":"https://artivis.github.io/publication/sola-18-lie/","publishdate":"2020-05-09T22:12:35.023827Z","relpermalink":"/publication/sola-18-lie/","section":"publication","summary":"A Lie group is an old mathematical abstract object dating back to the XIX century, when mathematician Sophus Lie laid the foundations of the theory of continuous transformation groups. As it often happens, its usage has spread over diverse areas of science and technology many years later. In robotics, we are recently experiencing an important trend in its usage, at least in the fields of estimation, and particularly in motion estimation for navigation. Yet for a vast majority of roboticians, Lie groups are highly abstract constructions and therefore difficult to understand and to use. This may be due to the fact that most of the literature on Lie theory is written by and for mathematicians and physicists, who might be more used than us to the deep abstractions this theory deals with. In estimation for robotics it is often not necessary to exploit the full capacity of the theory, and therefore an effort of selection of materials is required. In this paper, we will walk through the most basic principles of the Lie theory, with the aim of conveying clear and useful ideas, and leave a significant corpus of the Lie theory behind. Even with this mutilation, the material included here has proven to be extremely useful in modern estimation algorithms for robotics, especially in the fields of SLAM, visual odometry, and the like. Alongside this micro Lie theory, we provide a chapter with a few application examples, and a vast reference of formulas for the major Lie groups used in robotics, including most jacobian matrices and the way to easily manipulate them. We also present a new C++ template-only library implementing all the functionality described here.","tags":null,"title":"A micro Lie theory for state estimation in robotics","type":"publication"},{"authors":["J. Deray","J. SolÃ ","J. Andrade-Cetto"],"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589060872,"objectID":"6db2d53f82fb7607daaa1272edfece84","permalink":"https://artivis.github.io/publication/deray-ral-17/","publishdate":"2020-05-09T22:12:35.023482Z","relpermalink":"/publication/deray-ral-17/","section":"publication","summary":"We address in this letter the problem of loop closure detection for laser-based simultaneous localization and mapping (SLAM) of very large areas. Consistent with the state of the art, the map is encoded as a graph of poses, and to cope with very large mapping capabilities, loop closures are asserted by comparing the features extracted from a query laser scan against a previously acquired corpus of scan features using a bag-of-words (BoW) scheme. Two contributions are here presented. First, to benefit from the graph topology, feature frequency scores in the BoW are computed not only for each individual scan but also from neighboring scans in the SLAM graph. This has the effect of enforcing neighbor relational information during document matching. Second, a weak geometric check that takes into account feature ordering and occlusions is introduced that substantially improves loop closure detection performance. The two contributions are evaluated both separately and jointly on four common SLAM datasets and are shown to improve the state-of-the-art performance both in terms of precision and recall in most of the cases. Moreover, our current implementation is designed to work at nearly frame rate, allowing loop closure query resolution at nearly 22 Hz for the best case scenario and 2 Hz for the worst case scenario.","tags":null,"title":"Word ordering and document adjacency for large loop closure detection in 2D laser maps","type":"publication"},{"authors":["D. Gurung","C. Jiang","J. Deray","D. SidibÃ©"],"categories":null,"content":"","date":1370044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589060872,"objectID":"a126fbe7e6fa32b887faf2964b8e5fae","permalink":"https://artivis.github.io/publication/gurung-hal-00903898/","publishdate":"2020-05-09T22:12:35.023088Z","relpermalink":"/publication/gurung-hal-00903898/","section":"publication","summary":"In this project we develop a system that uses low cost web cameras to recognise gestures and track 2D orientations of the hand. This report is organized as such. First in section 2 we introduce various methods we undertook for hand detection. This is the most important step in hand gesture recognition. Results of various skin detection algorithms are discussed in length. This is followed by region extraction step (section 3). In this section approaches like contours and convex hull to extract region of interest which is hand are discussed. In section 4 a method is describe to recognize the open hand gesture. Two additional gestures of palm and fist are implemented using Haar-like features. These are discussed in section 5. In section 6 Kalman filter is introduced which tracks the centroid of hand region. The report is concluded by discussing about various issues related with the embraced approach (section 9) and future recommendations to improve the system is pointed out (section 10).","tags":null,"title":"Hand Gestures Recognition and Tracking","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589831268,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"https://artivis.github.io/about/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589831268,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://artivis.github.io/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]